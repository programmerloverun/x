(("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]=("undefined"!=typeof globalThis?globalThis:self)["makoChunk_@ant-design/x"]||[]).push([["67c621ad"],{"67c621ad":function(n,e,t){"use strict";t.d(e,"__esModule",{value:!0}),t.d(e,"texts",{enumerable:!0,get:function(){return a;}}),t("9db846f7");let a=[{value:"\u901A\u5E38\u60C5\u51B5 openai-node \u7528\u4E8E node \u73AF\u5883\uFF0C\u5982\u679C\u5728\u6D4F\u89C8\u5668\u73AF\u5883\u4F7F\u7528\uFF0C\u9700\u8981\u5F00\u542F ",paraId:0},{value:"dangerouslyAllowBrowser",paraId:0},{value:"\u3002",paraId:0},{value:"import { useXAgent, useXChat, Sender } from '@ant-design/x';\nimport OpenAI from 'openai';\n\nconst client = new OpenAI({\n  apiKey: process.env['OPENAI_API_KEY'],\n  dangerouslyAllowBrowser: true,\n});\n\n// react env ...\nconst [agent] = useXAgent({\n  request: async (info, callbacks) => {\n    const stream = await client.chat.completions.create({\n      model: 'gpt-4o',\n      messages: [{ role: 'user', content: 'Say this is a test' }],\n      stream: true,\n    });\n\n    for await (const chunk of stream) {\n      // \u8C03\u7528\u56DE\u8C03\n      callbacks.onUpdate(chunk.choices[0]?.delta?.content || '');\n    }\n  },\n});\n\nconst {\n  // \u7528\u4E8E\u53D1\u8D77\u5BF9\u8BDD\u8BF7\u6C42\n  onRequest,\n  // \u7528\u4E8E\u7ED1\u5B9A\u89C6\u56FE\n  messages,\n} = useXChat({ agent });\n\nconst items = messages.map((i) => ({\n  content: message,\n}));\n\nreturn (\n  <div>\n    <Bubble.List items={items} />\n    <Sender onSubmit={onRequest} />\n  </div>\n);\n",paraId:1,tocIndex:0},{value:"\u53C2\u8003 ",paraId:2,tocIndex:1},{value:"\u63A5\u5165\u517C\u5BB9 OpenAI \u7684\u6A21\u578B\u63A8\u7406\u670D\u52A1",paraId:3,tocIndex:1}];}}]);
//# sourceMappingURL=67c621ad-async.d496c252.js.map